{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":952401,"sourceType":"datasetVersion","datasetId":517172}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport random\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision import models, transforms\nfrom sklearn.metrics import classification_report, roc_auc_score\nfrom sklearn.model_selection import train_test_split\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\n# Set device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Path to dataset\ndata_dir = '/kaggle/input/diabetic-retinopathy-224x224-gaussian-filtered/gaussian_filtered_images/gaussian_filtered_images'\nclasses = ['Mild', 'Moderate', 'No_DR', 'Proliferate_DR', 'Severe']\n\n# Custom Dataset class\nclass DiabeticRetinopathyDataset(Dataset):\n    def __init__(self, file_paths, labels, transform=None):\n        self.file_paths = file_paths\n        self.labels = labels\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.file_paths)\n\n    def __getitem__(self, idx):\n        img_path = self.file_paths[idx]\n        label = self.labels[idx]\n        image = Image.open(img_path).convert(\"RGB\")\n\n        if self.transform:\n            image = self.transform(image)\n\n        return image, label\n\n# Data preprocessing and augmentation\ntransform = {\n    'train': transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomRotation(10),\n        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n    ]),\n    'test': transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n    ])\n}\n\n# Load dataset\nfile_paths = []\nlabels = []\n\nfor label, cls in enumerate(classes):\n    cls_folder = os.path.join(data_dir, cls)\n    for img_name in os.listdir(cls_folder):\n        file_paths.append(os.path.join(cls_folder, img_name))\n        labels.append(label)\n\n# Train-test split\ntrain_paths, val_paths, train_labels, val_labels = train_test_split(\n    file_paths, labels, test_size=0.2, stratify=labels, random_state=42\n)\n\n# Create datasets and dataloaders\ntrain_dataset = DiabeticRetinopathyDataset(train_paths, train_labels, transform=transform['train'])\nval_dataset = DiabeticRetinopathyDataset(val_paths, val_labels, transform=transform['test'])\n\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\nval_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)\n\n# Load pretrained model (ResNet50)\nmodel = models.resnet50(pretrained=True)\nnum_ftrs = model.fc.in_features\nmodel.fc = nn.Linear(num_ftrs, len(classes))\nmodel = model.to(device)\n\n# Loss function and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=1e-4)\n\n# Training and validation loop\ndef train_model(model, criterion, optimizer, num_epochs=20):\n    best_model_wts = model.state_dict()\n    best_acc = 0.0\n\n    for epoch in range(num_epochs):\n        print(f'Epoch {epoch + 1}/{num_epochs}')\n        print('-' * 10)\n\n        for phase in ['train', 'val']:\n            if phase == 'train':\n                model.train()\n                dataloader = train_loader\n            else:\n                model.eval()\n                dataloader = val_loader\n\n            running_loss = 0.0\n            running_corrects = 0\n\n            for inputs, labels in dataloader:\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n\n                optimizer.zero_grad()\n\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    _, preds = torch.max(outputs, 1)\n                    loss = criterion(outputs, labels)\n\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n\n            epoch_loss = running_loss / len(dataloader.dataset)\n            epoch_acc = running_corrects.double() / len(dataloader.dataset)\n\n            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n\n            if phase == 'val' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = model.state_dict()\n\n    print(f'Best val Acc: {best_acc:.4f}')\n    model.load_state_dict(best_model_wts)\n    return model\n\n# Train the model\nmodel = train_model(model, criterion, optimizer, num_epochs=20)\n\n# Save the model\ntorch.save(model.state_dict(), \"diabetic_retinopathy_model.pth\")\n\n# Evaluate the model\nmodel.eval()\nall_preds = []\nall_labels = []\n\nwith torch.no_grad():\n    for inputs, labels in val_loader:\n        inputs = inputs.to(device)\n        labels = labels.to(device)\n        outputs = model(inputs)\n        _, preds = torch.max(outputs, 1)\n        all_preds.extend(preds.cpu().numpy())\n        all_labels.extend(labels.cpu().numpy())\n\n# Classification report\nprint(\"Classification Report:\")\nprint(classification_report(all_labels, all_preds, target_names=classes))\n\n# Compute ROC AUC\nroc_auc = roc_auc_score(\n    np.eye(len(classes))[all_labels],\n    np.eye(len(classes))[all_preds],\n    multi_class='ovr'\n)\nprint(f\"ROC AUC Score: {roc_auc:.4f}\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"scrolled":true,"execution":{"iopub.status.busy":"2025-01-04T12:04:32.252106Z","iopub.execute_input":"2025-01-04T12:04:32.252433Z","iopub.status.idle":"2025-01-04T12:10:54.731554Z","shell.execute_reply.started":"2025-01-04T12:04:32.252407Z","shell.execute_reply":"2025-01-04T12:10:54.730481Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n100%|██████████| 97.8M/97.8M [00:00<00:00, 185MB/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/20\n----------\ntrain Loss: 0.7178 Acc: 0.7453\nval Loss: 0.6562 Acc: 0.7503\nEpoch 2/20\n----------\ntrain Loss: 0.5723 Acc: 0.7876\nval Loss: 0.5745 Acc: 0.7885\nEpoch 3/20\n----------\ntrain Loss: 0.5139 Acc: 0.7982\nval Loss: 0.5261 Acc: 0.7899\nEpoch 4/20\n----------\ntrain Loss: 0.4859 Acc: 0.8197\nval Loss: 0.4833 Acc: 0.8049\nEpoch 5/20\n----------\ntrain Loss: 0.4276 Acc: 0.8371\nval Loss: 0.5310 Acc: 0.7804\nEpoch 6/20\n----------\ntrain Loss: 0.3957 Acc: 0.8491\nval Loss: 0.5270 Acc: 0.8022\nEpoch 7/20\n----------\ntrain Loss: 0.3563 Acc: 0.8641\nval Loss: 0.5594 Acc: 0.7858\nEpoch 8/20\n----------\ntrain Loss: 0.3372 Acc: 0.8767\nval Loss: 0.5802 Acc: 0.8035\nEpoch 9/20\n----------\ntrain Loss: 0.3048 Acc: 0.8832\nval Loss: 0.7548 Acc: 0.8008\nEpoch 10/20\n----------\ntrain Loss: 0.2687 Acc: 0.9013\nval Loss: 0.5863 Acc: 0.8117\nEpoch 11/20\n----------\ntrain Loss: 0.2586 Acc: 0.8996\nval Loss: 0.6786 Acc: 0.7831\nEpoch 12/20\n----------\ntrain Loss: 0.2312 Acc: 0.9184\nval Loss: 0.7573 Acc: 0.7967\nEpoch 13/20\n----------\ntrain Loss: 0.2095 Acc: 0.9276\nval Loss: 0.6526 Acc: 0.8035\nEpoch 14/20\n----------\ntrain Loss: 0.1997 Acc: 0.9280\nval Loss: 0.7085 Acc: 0.7844\nEpoch 15/20\n----------\ntrain Loss: 0.1920 Acc: 0.9307\nval Loss: 0.6950 Acc: 0.8063\nEpoch 16/20\n----------\ntrain Loss: 0.1616 Acc: 0.9403\nval Loss: 0.6868 Acc: 0.7885\nEpoch 17/20\n----------\ntrain Loss: 0.1521 Acc: 0.9447\nval Loss: 0.7484 Acc: 0.8022\nEpoch 18/20\n----------\ntrain Loss: 0.1271 Acc: 0.9560\nval Loss: 0.9009 Acc: 0.7981\nEpoch 19/20\n----------\ntrain Loss: 0.1284 Acc: 0.9536\nval Loss: 0.8258 Acc: 0.7926\nEpoch 20/20\n----------\ntrain Loss: 0.1227 Acc: 0.9556\nval Loss: 0.8303 Acc: 0.7858\nBest val Acc: 0.8117\nClassification Report:\n                precision    recall  f1-score   support\n\n          Mild       0.59      0.54      0.56        74\n      Moderate       0.70      0.74      0.72       200\n         No_DR       0.96      0.97      0.97       361\nProliferate_DR       0.41      0.53      0.46        59\n        Severe       0.38      0.15      0.22        39\n\n      accuracy                           0.79       733\n     macro avg       0.61      0.59      0.59       733\n  weighted avg       0.78      0.79      0.78       733\n\nROC AUC Score: 0.7659\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}